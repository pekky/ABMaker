# -*- coding: utf-8 -*-
"""
é«˜é€Ÿä¼˜åŒ–ç‰ˆæœ‰å£°è¯»ç‰©åˆ¶ä½œå™¨ - ä½¿ç”¨å°æ¨¡å‹å’Œä¼˜åŒ–è®¾ç½®
"""
import os
import argparse
import json
import time
from datetime import datetime
from typing import List
from smart_pdf_extractor import SmartPDFExtractor
from text_processor import TextProcessor
from audio_generator import AudioGenerator


class FastOptimizedAudiobookMaker:
    """é«˜é€Ÿä¼˜åŒ–ç‰ˆæœ‰å£°è¯»ç‰©åˆ¶ä½œå™¨"""
    
    def __init__(self, voice_preset: str = "v2/en_speaker_6", 
                 max_chars: int = 300,  # å¢åŠ ç‰‡æ®µå¤§å°å‡å°‘ç‰‡æ®µæ•°é‡
                 target_tokens: int = 40000,
                 resume: bool = True):
        """
        åˆå§‹åŒ–é«˜é€Ÿä¼˜åŒ–ç‰ˆåˆ¶ä½œå™¨
        
        Args:
            voice_preset: è¯­éŸ³é¢„è®¾
            max_chars: æ¯ä¸ªç‰‡æ®µçš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆå¢åŠ åˆ°300ï¼‰
            target_tokens: ç›®æ ‡tokenæ•°ï¼ˆ4ä¸‡ï¼‰
            resume: æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        """
        self.voice_preset = voice_preset
        self.max_chars = max_chars
        self.target_tokens = target_tokens
        self.resume = resume
        
        self.text_processor = TextProcessor(max_chars=max_chars)
        # ä½¿ç”¨å°æ¨¡å‹æå‡é€Ÿåº¦
        self.audio_generator = AudioGenerator(voice_preset=voice_preset, use_small_model=True)
        
        # çŠ¶æ€æ–‡ä»¶è·¯å¾„
        self.state_file = "fast_optimized_processing_state.json"
        self.output_dir = "fast_optimized_audio_files"
        
    def save_state(self, state: dict):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    
    def load_state(self) -> dict:
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        if os.path.exists(self.state_file):
            with open(self.state_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        import re
        
        # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        
        # ç»Ÿè®¡è‹±æ–‡å•è¯
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
        
        # ä¼°ç®—tokenæ•°
        estimated_tokens = chinese_chars + int(english_words * 1.3)
        
        return estimated_tokens
    
    def create_token_batches(self, structure_data: dict) -> List[dict]:
        """æŒ‰4ä¸‡tokenåˆ›å»ºæ‰¹æ¬¡ï¼Œä¿è¯é¡µé¢æˆ–æ®µè½å®Œæ•´æ€§"""
        pages = structure_data['pages']
        has_page_numbers = structure_data['has_page_numbers']
        
        batches = []
        current_batch = {
            'pages': [],
            'paragraphs': [],
            'text': '',
            'token_count': 0,
            'char_count': 0,
            'start_page': None,
            'end_page': None,
            'start_para': None,
            'end_para': None
        }
        
        print(f"\nå¼€å§‹åˆ›å»º4ä¸‡tokenæ‰¹æ¬¡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰...")
        print(f"ç›®æ ‡tokenæ•°: {self.target_tokens:,}")
        print(f"æ¯ç‰‡æ®µæœ€å¤§å­—ç¬¦æ•°: {self.max_chars}")
        print(f"é¡µç æ£€æµ‹: {'æœ‰' if has_page_numbers else 'æ— '}")
        
        for page_idx, page_data in enumerate(pages):
            page_text = page_data['text']
            page_tokens = self.estimate_tokens(page_text)
            page_chars = len(page_text)
            
            # å¦‚æœæ·»åŠ å½“å‰é¡µä¼šè¶…è¿‡ç›®æ ‡tokenæ•°ï¼Œä¸”å½“å‰æ‰¹æ¬¡ä¸ä¸ºç©º
            if current_batch['token_count'] + page_tokens > self.target_tokens and current_batch['pages']:
                # å®Œæˆå½“å‰æ‰¹æ¬¡
                current_batch['end_page'] = current_batch['pages'][-1]['page_num']
                batches.append(current_batch.copy())
                
                # å¼€å§‹æ–°æ‰¹æ¬¡
                current_batch = {
                    'pages': [page_data],
                    'paragraphs': page_data['paragraphs'].copy(),
                    'text': page_text,
                    'token_count': page_tokens,
                    'char_count': page_chars,
                    'start_page': page_data['page_num'],
                    'end_page': None,
                    'start_para': 0,
                    'end_para': len(page_data['paragraphs']) - 1
                }
            else:
                # æ·»åŠ å½“å‰é¡µåˆ°æ‰¹æ¬¡
                if not current_batch['pages']:
                    current_batch['start_page'] = page_data['page_num']
                    current_batch['start_para'] = 0
                
                current_batch['pages'].append(page_data)
                current_batch['paragraphs'].extend(page_data['paragraphs'])
                current_batch['text'] += '\n\n' + page_text if current_batch['text'] else page_text
                current_batch['token_count'] += page_tokens
                current_batch['char_count'] += page_chars
                current_batch['end_page'] = page_data['page_num']
                current_batch['end_para'] = len(current_batch['paragraphs']) - 1
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch['pages']:
            batches.append(current_batch)
        
        print(f"âœ“ 4ä¸‡tokenæ‰¹æ¬¡åˆ›å»ºå®Œæˆï¼Œå…± {len(batches)} æ‰¹")
        
        # æ‰“å°æ‰¹æ¬¡ä¿¡æ¯
        for i, batch in enumerate(batches, 1):
            if has_page_numbers:
                print(f"æ‰¹æ¬¡ {i}: ç¬¬{batch['start_page']}-{batch['end_page']}é¡µ, "
                      f"{batch['token_count']:,}tokens, {batch['char_count']:,}å­—ç¬¦")
            else:
                print(f"æ‰¹æ¬¡ {i}: ç¬¬{batch['start_page']}-{batch['end_page']}é¡µ, "
                      f"{len(batch['paragraphs'])}ä¸ªæ®µè½, "
                      f"{batch['token_count']:,}tokens, {batch['char_count']:,}å­—ç¬¦")
        
        return batches
    
    def create_audiobook_fast(self, pdf_path: str, output_dir: str = "fast_optimized_audio_files",
                            keep_chunks: bool = False) -> List[str]:
        """é«˜é€Ÿåˆ›å»ºæœ‰å£°è¯»ç‰©"""
        print("=" * 60)
        print(f"ğŸš€ å¼€å§‹é«˜é€Ÿä¼˜åŒ–ç‰ˆæœ‰å£°è¯»ç‰©åˆ¶ä½œ")
        print("=" * 60)
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        state = self.load_state() if self.resume else {}
        
        # æ­¥éª¤1: æ™ºèƒ½æå–PDFæ–‡æœ¬
        if 'batches' not in state:
            print("\næ­¥éª¤ 1/3: æ™ºèƒ½æå–PDFæ–‡æœ¬")
            print("-" * 60)
            
            extractor = SmartPDFExtractor(pdf_path)
            structure_data = extractor.extract_text_with_structure()
            batches = self.create_token_batches(structure_data)
            
            # ä¿å­˜çŠ¶æ€
            state['batches'] = batches
            state['total_batches'] = len(batches)
            state['processed_batches'] = 0
            state['completed_batches'] = []
            state['start_time'] = datetime.now().isoformat()
            state['has_page_numbers'] = structure_data['has_page_numbers']
            self.save_state(state)
            
            print(f"âœ“ 4ä¸‡tokenæ‰¹æ¬¡åˆ›å»ºå®Œæˆï¼Œå…± {len(batches)} æ‰¹")
            print(f"âœ“ é¡µç æ£€æµ‹: {'æœ‰' if structure_data['has_page_numbers'] else 'æ— '}")
            print(f"âœ“ å¹³å‡æ¯æ‰¹: {sum(batch['token_count'] for batch in batches) / len(batches):.0f} tokens")
        else:
            batches = state['batches']
            print(f"\nâœ“ æ¢å¤å¤„ç†ï¼Œå…± {len(batches)} æ‰¹")
            print(f"âœ“ å·²å®Œæˆ {state['processed_batches']} æ‰¹")
        
        # æ­¥éª¤2: æŒ‰æ‰¹æ¬¡ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        print("\næ­¥éª¤ 2/3: é«˜é€Ÿç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
        print("-" * 60)
        
        os.makedirs(output_dir, exist_ok=True)
        total_batches = len(batches)
        processed_batches = state.get('processed_batches', 0)
        
        print(f"æ€»æ‰¹æ¬¡æ•°: {total_batches}")
        print(f"å¤„ç†æ¨¡å¼: å°æ¨¡å‹é«˜é€Ÿæ¨¡å¼")
        print(f"æ¯ç‰‡æ®µå­—ç¬¦æ•°: {self.max_chars}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        audio_files = []
        
        for batch_idx in range(processed_batches, total_batches):
            batch = batches[batch_idx]
            
            print(f"\n--- å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ---")
            if state.get('has_page_numbers', False):
                print(f"é¡µé¢èŒƒå›´: ç¬¬{batch['start_page']}-{batch['end_page']}é¡µ")
            else:
                print(f"é¡µé¢èŒƒå›´: ç¬¬{batch['start_page']}-{batch['end_page']}é¡µ")
                print(f"æ®µè½æ•°: {len(batch['paragraphs'])}ä¸ªæ®µè½")
            print(f"Tokenæ•°: {batch['token_count']:,}tokens")
            print(f"å­—ç¬¦æ•°: {batch['char_count']:,}å­—ç¬¦")
            
            # å°†æ‰¹æ¬¡æ–‡æœ¬åˆ†å‰²æˆç‰‡æ®µï¼ˆæ›´å¤§çš„ç‰‡æ®µï¼‰
            batch_chunks = self.text_processor.split_into_chunks(batch['text'])
            print(f"ç‰‡æ®µæ•°: {len(batch_chunks)}ä¸ªç‰‡æ®µ")
            
            # ç”Ÿæˆå½“å‰æ‰¹æ¬¡çš„éŸ³é¢‘ï¼ˆé«˜é€Ÿæ¨¡å¼ï¼‰
            batch_start_time = time.time()
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_chunk_dir = os.path.join(output_dir, f"batch_{batch_idx + 1:03d}_chunks")
            os.makedirs(temp_chunk_dir, exist_ok=True)
            
            # é€ä¸ªç”ŸæˆéŸ³é¢‘ç‰‡æ®µ
            batch_audio_files = []
            for i, chunk in enumerate(batch_chunks):
                try:
                    # ç”Ÿæˆå•ä¸ªéŸ³é¢‘ç‰‡æ®µ
                    audio_array = self.audio_generator.generate_single_audio(chunk)
                    
                    # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
                    chunk_path = os.path.join(temp_chunk_dir, f"chunk_{i:04d}.wav")
                    from scipy.io import wavfile
                    wavfile.write(chunk_path, self.audio_generator.sample_rate, audio_array)
                    batch_audio_files.append(chunk_path)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if (i + 1) % 20 == 0 or i == len(batch_chunks) - 1:
                        progress = (i + 1) / len(batch_chunks) * 100
                        print(f"  è¿›åº¦: {i + 1}/{len(batch_chunks)} ({progress:.1f}%)")
                        
                except Exception as e:
                    print(f"  é”™è¯¯: ç”Ÿæˆç‰‡æ®µ {i} å¤±è´¥ - {e}")
                    # åˆ›å»ºä¸€ä¸ªé™éŸ³ç‰‡æ®µä½œä¸ºå ä½ç¬¦
                    chunk_path = os.path.join(temp_chunk_dir, f"chunk_{i:04d}.wav")
                    from scipy.io import wavfile
                    import numpy as np
                    silence = np.zeros(int(0.5 * self.audio_generator.sample_rate), dtype=np.float32)
                    wavfile.write(chunk_path, self.audio_generator.sample_rate, silence)
                    batch_audio_files.append(chunk_path)
            
            # åˆå¹¶å½“å‰æ‰¹æ¬¡çš„éŸ³é¢‘
            batch_output_path = os.path.join(output_dir, f"batch_{batch_idx + 1:03d}.wav")
            merged_audio = self.audio_generator.merge_audio_files(
                batch_audio_files, 
                batch_output_path,
                silence_duration=0.1  # å‡å°‘é™éŸ³æ—¶é—´
            )
            
            batch_time = time.time() - batch_start_time
            print(f"âœ“ æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆï¼Œè€—æ—¶: {batch_time/60:.1f} åˆ†é’Ÿ")
            print(f"âœ“ å¹³å‡æ¯ç‰‡æ®µ: {batch_time/len(batch_chunks):.2f} ç§’")
            print(f"âœ“ å¤„ç†é€Ÿåº¦: {len(batch_chunks)/batch_time:.1f} it/s")
            print(f"âœ“ è¾“å‡ºæ–‡ä»¶: {batch_output_path}")
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            if merged_audio:
                audio_files.append(batch_output_path)
            
            # æ›´æ–°çŠ¶æ€
            state['processed_batches'] = batch_idx + 1
            state['completed_batches'].append(batch_idx)
            state['last_update'] = datetime.now().isoformat()
            self.save_state(state)
            
            # æ¸…ç†ä¸´æ—¶ç‰‡æ®µæ–‡ä»¶
            if not keep_chunks and batch_audio_files:
                import shutil
                if os.path.exists(temp_chunk_dir):
                    shutil.rmtree(temp_chunk_dir)
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼ˆå‡å°‘ä¼‘æ¯æ—¶é—´ï¼‰
            if batch_idx < total_batches - 1:
                print("æ‰¹æ¬¡é—´ä¼‘æ¯ 1 ç§’...")
                time.sleep(1)
        
        # æ­¥éª¤3: ç”Ÿæˆæ‰¹æ¬¡åˆ—è¡¨æ–‡ä»¶
        print("\næ­¥éª¤ 3/3: ç”Ÿæˆæ‰¹æ¬¡åˆ—è¡¨æ–‡ä»¶")
        print("-" * 60)
        
        # ç”Ÿæˆæ‰¹æ¬¡ä¿¡æ¯æ–‡ä»¶
        batch_info = {
            'total_batches': total_batches,
            'audio_files': audio_files,
            'batches': []
        }
        
        for i, batch in enumerate(batches):
            batch_info['batches'].append({
                'batch_number': i + 1,
                'audio_file': audio_files[i] if i < len(audio_files) else None,
                'page_range': f"{batch['start_page']}-{batch['end_page']}",
                'token_count': batch['token_count'],
                'char_count': batch['char_count'],
                'paragraph_count': len(batch['paragraphs'])
            })
        
        # ä¿å­˜æ‰¹æ¬¡ä¿¡æ¯
        info_file = os.path.join(output_dir, "batch_info.json")
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(batch_info, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆæ’­æ”¾åˆ—è¡¨æ–‡ä»¶
        playlist_file = os.path.join(output_dir, "playlist.m3u")
        with open(playlist_file, 'w', encoding='utf-8') as f:
            f.write("#EXTM3U\n")
            for i, audio_file in enumerate(audio_files, 1):
                f.write(f"#EXTINF:-1,æ‰¹æ¬¡ {i}\n")
                f.write(f"{os.path.basename(audio_file)}\n")
        
        # æ¸…ç†çŠ¶æ€æ–‡ä»¶
        if not keep_chunks and os.path.exists(self.state_file):
            os.remove(self.state_file)
        
        # è®¡ç®—æ€»è€—æ—¶
        if 'start_time' in state:
            start_time = datetime.fromisoformat(state['start_time'])
            total_time = datetime.now() - start_time
            total_tokens = sum(batch['token_count'] for batch in batches)
            total_chunks = sum(len(self.text_processor.split_into_chunks(batch['text'])) for batch in batches)
            
            print(f"\nâœ“ æ€»è€—æ—¶: {total_time.total_seconds()/3600:.1f} å°æ—¶")
            print(f"âœ“ æ€»Tokenæ•°: {total_tokens:,}tokens")
            print(f"âœ“ æ€»ç‰‡æ®µæ•°: {total_chunks:,}ä¸ªç‰‡æ®µ")
            print(f"âœ“ å¹³å‡æ¯ç‰‡æ®µ: {total_time.total_seconds()/total_chunks:.2f} ç§’")
            print(f"âœ“ æ€»å¤„ç†é€Ÿåº¦: {total_chunks/total_time.total_seconds():.1f} it/s")
        
        print("\n" + "=" * 60)
        print(f"ğŸš€ é«˜é€Ÿä¼˜åŒ–ç‰ˆæœ‰å£°è¯»ç‰©åˆ¶ä½œå®Œæˆï¼")
        print(f"è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
        print(f"éŸ³é¢‘æ–‡ä»¶: {len(audio_files)}ä¸ª")
        print(f"æ‰¹æ¬¡ä¿¡æ¯: {info_file}")
        print(f"æ’­æ”¾åˆ—è¡¨: {playlist_file}")
        print("=" * 60)
        
        return audio_files


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description="é«˜é€Ÿä¼˜åŒ–ç‰ˆPDFå°è¯´è½¬æœ‰å£°è¯»ç‰©å·¥å…·")
    parser.add_argument("pdf_file", help="PDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output-dir", default="fast_optimized_audio_files", 
                       help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: fast_optimized_audio_filesï¼‰")
    parser.add_argument("-v", "--voice", default="v2/en_speaker_6", 
                       help="è¯­éŸ³é¢„è®¾ï¼ˆé»˜è®¤: v2/en_speaker_6ï¼‰")
    parser.add_argument("-c", "--max-chars", type=int, default=300,
                       help="æ¯ä¸ªç‰‡æ®µçš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤: 300ï¼‰")
    parser.add_argument("-t", "--target-tokens", type=int, default=40000,
                       help="ç›®æ ‡tokenæ•°ï¼ˆé»˜è®¤: 40000ï¼‰")
    parser.add_argument("--keep-chunks", action="store_true",
                       help="ä¿ç•™éŸ³é¢‘ç‰‡æ®µæ–‡ä»¶")
    parser.add_argument("--no-resume", action="store_true",
                       help="ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.pdf_file):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {args.pdf_file}")
        return
    
    # åˆ›å»ºé«˜é€Ÿä¼˜åŒ–ç‰ˆåˆ¶ä½œå™¨
    maker = FastOptimizedAudiobookMaker(
        voice_preset=args.voice,
        max_chars=args.max_chars,
        target_tokens=args.target_tokens,
        resume=not args.no_resume
    )
    
    maker.create_audiobook_fast(
        pdf_path=args.pdf_file,
        output_dir=args.output_dir,
        keep_chunks=args.keep_chunks
    )


if __name__ == "__main__":
    main()
