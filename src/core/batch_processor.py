# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¤„ç†æ¨¡å— - å°†é•¿æ–‡æ¡£åˆ†å‰²æˆå¤šä¸ªbatchè¿›è¡Œå¤„ç†
"""
import os
import sys
import re
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from utils.config_manager import ConfigManager


class BatchProcessor:
    """æ‰¹é‡å¤„ç†å™¨ - å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªbatch"""
    
    def __init__(self, config_manager=None):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config_manager = config_manager or ConfigManager()
        self.batch_config = self.config_manager.get_batch_config()
        
        # æ‰¹é‡å¤„ç†å‚æ•°
        self.enable_batch = self.batch_config.get("enable_batch_processing", True)
        self.batch_size_chars = self.batch_config.get("batch_size_chars", 15000)
        self.batch_size_tokens = self.batch_config.get("batch_size_tokens", 15000)
        self.batch_overlap_chars = self.batch_config.get("batch_overlap_chars", 200)
        self.min_batch_size = self.batch_config.get("min_batch_size", 5000)
        self.max_batch_size = self.batch_config.get("max_batch_size", 20000)
        
        # åˆ†å‰²ç­–ç•¥
        self.split_at_paragraphs = self.batch_config.get("split_at_paragraphs", True)
        self.split_at_chapters = self.batch_config.get("split_at_chapters", True)
        
        # è¾“å‡ºè®¾ç½®
        self.batch_prefix = self.batch_config.get("batch_output_prefix", "batch_")
        self.batch_suffix = self.batch_config.get("batch_output_suffix", "_audiobook.wav")
        self.create_final_merge = self.batch_config.get("create_final_merge", True)
        self.final_output_name = self.batch_config.get("final_output_name", "complete_audiobook.wav")
    
    def split_into_batches(self, text: str) -> List[str]:
        """
        å°†æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªbatch
        
        Args:
            text: å®Œæ•´æ–‡æœ¬
            
        Returns:
            batchæ–‡æœ¬åˆ—è¡¨
        """
        if not self.enable_batch:
            return [text]
        
        print(f"\nğŸ“¦ å¼€å§‹æ‰¹é‡åˆ†å‰²ï¼Œç›®æ ‡batchå¤§å°: {self.batch_size_tokens} tokens")
        
        # é¦–å…ˆæŒ‰æ®µè½åˆ†å‰²
        paragraphs = self._split_into_paragraphs(text)
        print(f"âœ“ æ–‡æœ¬å·²åˆ†å‰²æˆ {len(paragraphs)} ä¸ªæ®µè½")
        
        # ç„¶åç»„åˆæˆbatch
        batches = self._combine_into_batches(paragraphs)
        print(f"âœ“ æ–‡æœ¬å·²åˆ†å‰²æˆ {len(batches)} ä¸ªbatch")
        
        # æ˜¾ç¤ºbatchä¿¡æ¯
        for i, batch in enumerate(batches, 1):
            estimated_tokens = self._estimate_tokens(batch)
            print(f"  Batch {i}: {len(batch)} å­—ç¬¦, ~{estimated_tokens} tokens")
        
        return batches
    
    def _split_into_paragraphs(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆæ®µè½"""
        # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²æ®µè½
        paragraphs = re.split(r'\n\s*\n', text)
        
        # æ¸…ç†ç©ºæ®µè½
        paragraphs = [p.strip() for p in paragraphs if p.strip()]
        
        return paragraphs
    
    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼ˆç²—ç•¥ä¼°ç®—ï¼š1ä¸ªtoken â‰ˆ 4ä¸ªå­—ç¬¦ï¼‰"""
        return len(text) // 4
    
    def _combine_into_batches(self, paragraphs: List[str]) -> List[str]:
        """å°†æ®µè½ç»„åˆæˆbatchï¼ˆåŸºäºtokenæ•°é‡ï¼‰"""
        batches = []
        current_batch = ""
        current_tokens = 0
        
        for paragraph in paragraphs:
            paragraph_tokens = self._estimate_tokens(paragraph)
            paragraph_chars = len(paragraph)
            
            # å¦‚æœå½“å‰æ®µè½å¤ªå¤§ï¼Œéœ€è¦åˆ†å‰²
            if paragraph_chars > self.max_batch_size:
                # å…ˆä¿å­˜å½“å‰batch
                if current_batch.strip():
                    batches.append(current_batch.strip())
                    current_batch = ""
                    current_tokens = 0
                
                # åˆ†å‰²å¤§æ®µè½
                sub_batches = self._split_large_paragraph(paragraph)
                batches.extend(sub_batches)
                continue
            
            # æ£€æŸ¥æ·»åŠ å½“å‰æ®µè½æ˜¯å¦ä¼šè¶…è¿‡batch tokenæ•°é‡
            if current_tokens + paragraph_tokens > self.batch_size_tokens:
                # ä¿å­˜å½“å‰batch
                if current_batch.strip():
                    batches.append(current_batch.strip())
                
                # å¼€å§‹æ–°batch
                current_batch = paragraph
                current_tokens = paragraph_tokens
            else:
                # æ·»åŠ åˆ°å½“å‰batch
                if current_batch:
                    current_batch += "\n\n" + paragraph
                else:
                    current_batch = paragraph
                current_tokens += paragraph_tokens
        
        # ä¿å­˜æœ€åä¸€ä¸ªbatch
        if current_batch.strip():
            batches.append(current_batch.strip())
        
        # è¿‡æ»¤å¤ªå°çš„batch
        filtered_batches = []
        for batch in batches:
            if len(batch) >= self.min_batch_size:
                filtered_batches.append(batch)
            else:
                # å¦‚æœbatchå¤ªå°ï¼Œå°è¯•ä¸å‰ä¸€ä¸ªbatchåˆå¹¶
                if filtered_batches and len(filtered_batches[-1]) + len(batch) <= self.max_batch_size:
                    filtered_batches[-1] += "\n\n" + batch
                else:
                    # å¦‚æœæ— æ³•åˆå¹¶ï¼Œä»ç„¶ä¿ç•™ï¼ˆé¿å…ä¸¢å¤±å†…å®¹ï¼‰
                    filtered_batches.append(batch)
        
        return filtered_batches
    
    def _split_large_paragraph(self, paragraph: str) -> List[str]:
        """åˆ†å‰²è¿‡å¤§çš„æ®µè½"""
        if len(paragraph) <= self.max_batch_size:
            return [paragraph]
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]\s*', paragraph)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        batches = []
        current_batch = ""
        current_size = 0
        
        for sentence in sentences:
            sentence_size = len(sentence)
            
            if current_size + sentence_size > self.max_batch_size:
                if current_batch.strip():
                    batches.append(current_batch.strip())
                current_batch = sentence
                current_size = sentence_size
            else:
                if current_batch:
                    current_batch += ". " + sentence
                else:
                    current_batch = sentence
                current_size += sentence_size
        
        if current_batch.strip():
            batches.append(current_batch.strip())
        
        return batches
    
    def get_batch_output_path(self, batch_index: int, base_name: str = "") -> str:
        """
        è·å–batchè¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Args:
            batch_index: batchç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
            base_name: åŸºç¡€æ–‡ä»¶å
            
        Returns:
            batchè¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if base_name:
            # ç§»é™¤æ‰©å±•å
            base_name = os.path.splitext(base_name)[0]
            filename = f"{self.batch_prefix}{base_name}_{batch_index:03d}{self.batch_suffix}"
        else:
            filename = f"{self.batch_prefix}{batch_index:03d}{self.batch_suffix}"
        
        return filename
    
    def get_final_output_path(self, base_name: str = "") -> str:
        """
        è·å–æœ€ç»ˆåˆå¹¶æ–‡ä»¶è·¯å¾„
        
        Args:
            base_name: åŸºç¡€æ–‡ä»¶å
            
        Returns:
            æœ€ç»ˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if base_name:
            base_name = os.path.splitext(base_name)[0]
            return f"{base_name}_{self.final_output_name}"
        else:
            return self.final_output_name


def main():
    """æµ‹è¯•æ‰¹é‡å¤„ç†å™¨"""
    processor = BatchProcessor()
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    è¿™æ˜¯ç¬¬ä¸€æ®µæ–‡æœ¬ã€‚å®ƒåŒ…å«äº†ä¸€äº›å†…å®¹ã€‚
    
    è¿™æ˜¯ç¬¬äºŒæ®µæ–‡æœ¬ã€‚å®ƒæ¯”ç¬¬ä¸€æ®µè¦é•¿ä¸€äº›ï¼ŒåŒ…å«äº†æ›´å¤šçš„å†…å®¹ã€‚
    
    è¿™æ˜¯ç¬¬ä¸‰æ®µæ–‡æœ¬ã€‚å®ƒéå¸¸é•¿ï¼ŒåŒ…å«äº†å¾ˆå¤šå†…å®¹ï¼Œç”¨æ¥æµ‹è¯•æ‰¹é‡åˆ†å‰²åŠŸèƒ½ã€‚
    
    è¿™æ˜¯ç¬¬å››æ®µæ–‡æœ¬ã€‚
    
    è¿™æ˜¯ç¬¬äº”æ®µæ–‡æœ¬ã€‚
    """ * 100  # é‡å¤100æ¬¡ä»¥å¢åŠ é•¿åº¦
    
    print("ğŸ§ª æ‰¹é‡å¤„ç†å™¨æµ‹è¯•")
    print("=" * 50)
    print(f"åŸå§‹æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    
    batches = processor.split_into_batches(test_text)
    
    print(f"\nâœ“ åˆ†å‰²å®Œæˆï¼Œå…± {len(batches)} ä¸ªbatch")
    for i, batch in enumerate(batches, 1):
        print(f"  Batch {i}: {len(batch)} å­—ç¬¦")
        print(f"    è¾“å‡ºæ–‡ä»¶: {processor.get_batch_output_path(i, 'test')}")


if __name__ == "__main__":
    main()

